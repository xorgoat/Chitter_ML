{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/xorgoat/Chitter_ML/blob/un-resized-spectrograms-patch-1/birdspectrogrammodelpatch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdWnTOPb7wT9",
    "outputId": "a370f6a8-a8b4-41e5-c17e-bdbb5ab24ad4"
   },
   "outputs": [],
   "source": [
    "#Define the folder where you saved the data in\n",
    "path = \"C:\\\\Users\\\\arice\\\\OneDrive\\\\Documents\\\\Chitter_ML data\\\\bird_spectrograms\\\\\"\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive')\n",
    "#!ln -s \"/gdrive/My Drive/Chitter_ML Data\" \"/content/Chitter_ML Data\"\n",
    "\n",
    "#path = \"/content/Chitter_ML Data/_final_bird_audio/spectrograms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/floris/Documents/GitHub/insect_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40GYyq2NBKMu"
   },
   "outputs": [],
   "source": [
    "#basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "#for images\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import resize\n",
    "\n",
    "#Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#Model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydUvZn4p0_jR"
   },
   "source": [
    "### SDV (Singular Value Decomposition - compressing images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kE61qaDwLous"
   },
   "outputs": [],
   "source": [
    "#have to do this before x y assignment\n",
    "#tried variance threshold too, but will not be using as it is a hassle for our type of data\n",
    "\n",
    "#trying to compress color channels with SVD here\n",
    "#also see https://stackabuse.com/dimensionality-reduction-in-python-with-scikit-learn/\n",
    "from PIL import Image\n",
    "\n",
    "#get colors\n",
    "def color_isolation(img_file):\n",
    "  img = Image.open(img_file)\n",
    "  #display(img)\n",
    "  im_array = np.array(img)\n",
    "  red = im_array[:, :, 0]\n",
    "  green = im_array[:, :, 1]\n",
    "  blue = im_array[:, :, 2]\n",
    "  return red, green, blue\n",
    "\n",
    "#compress color channels\n",
    "def compress_channel(color_channel, n):\n",
    "  u, s, v = np.linalg.svd(color_channel)\n",
    "  compressed = np.zeros((color_channel.shape[0], color_channel.shape[1]))\n",
    "\n",
    "  left_matrix = np.matmul(u[:, 0:n], np.diag(s)[0:n, 0:n])\n",
    "  inner_compressed = np.matmul(left_matrix, v[0:n, :])\n",
    "  compressed = inner_compressed.astype('uint8')\n",
    "\n",
    "  return compressed\n",
    "\n",
    "#put compressed color channels into image\n",
    "def compress_image(red, green, blue, n):\n",
    "  compressed_red = compress_channel(red, n)\n",
    "  compressed_green = compress_channel(green, n)\n",
    "  compressed_blue = compress_channel(blue, n)\n",
    "\n",
    "  im_red = Image.fromarray(compressed_red)\n",
    "  im_blue = Image.fromarray(compressed_blue)\n",
    "  im_green = Image.fromarray(compressed_green)\n",
    "\n",
    "  new_image = Image.merge(\"RGB\", (im_red, im_green, im_blue))\n",
    "  #new_image.show()\n",
    "\n",
    "  return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "u2PtOeDk7IfL",
    "outputId": "bd84c36e-0ce6-4a47-f941-a61b0a5af97a"
   },
   "outputs": [],
   "source": [
    "#example for finding the right n\n",
    "path_img = path + \"/test/azanicadazuluensis/Azanicadazuluensis_MHV_20936_20A.zuluensis_20Mission_20Rock_20_23.png\"\n",
    "\n",
    "red, green, blue = color_isolation(path_img) \n",
    "img = Image.open(path_img)\n",
    "display(img)\n",
    "n = 20\n",
    "new_image = compress_image(red, green, blue, n)\n",
    "display(new_image) #do NOT use img.show() https://stackoverflow.com/questions/60034512/cant-show-an-image-using-pil-on-google-colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGNPUGGH1x1w"
   },
   "source": [
    "### X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "PKZ2bBNCrhSK",
    "outputId": "7c87b153-4ca0-4f4a-b6f1-dfe2c306d6ce"
   },
   "outputs": [],
   "source": [
    "#going through train images and calling functions\n",
    "train_path = path + \"/\" + \"train\"\n",
    "new_directory = \"C:/Users/Floris/Documents/GitHub/insect_audio/spectrograms_compressed/train\" #change if your path is different\n",
    "plt.axis('off')\n",
    "\n",
    "#Defining X_train y_train\n",
    "X_train = []  #creating a list for the images\n",
    "y_train = []  #creating the labels\n",
    "\n",
    "#go through every bird in every species\n",
    "for species in os.listdir(train_path):\n",
    "    folder_path = os.path.join(train_path, species) \n",
    "    try:\n",
    "      new_folder = os.path.join(new_directory, species)\n",
    "      os.makedirs(new_folder)\n",
    "    except: #if directory already exists, just continue\n",
    "      pass\n",
    "    for insect_image in os.listdir(folder_path):\n",
    "      image_path = os.path.join(folder_path, insect_image)\n",
    "      img = mpimg.imread(image_path) #turning image into array\n",
    "      X_train.append(img)\n",
    "      y_train.append(species)\n",
    "\n",
    "      #SDV\n",
    "      new_path = os.path.join(new_folder, insect_image)\n",
    "      red, green, blue = color_isolation(image_path) \n",
    "      n = 5 #limit of image compression (closer to 0 is higher degree), needs to be lower than lowest dimension of pixels (217)\n",
    "      new_image = compress_image(red, green, blue, n)\n",
    "      new_image.save(new_path)\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "print(X_train_np.shape) #output dimensions (number of images,pixels_x,pixels_y,rgb)\n",
    "print(y_train_np.shape) #output dimensions (number of images,)\n",
    "\n",
    "print(\"\\nExample:\")\n",
    "img_train = X_train_np[0]\n",
    "plt.imshow(img_train)\n",
    "print(y_train_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwRhXT7JAGy2"
   },
   "source": [
    "### X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "_e1yLbfpBN1y",
    "outputId": "20196e36-4cff-4604-ed9b-e70a2b173453"
   },
   "outputs": [],
   "source": [
    "#going through test images and calling functions\n",
    "test_path = os.path.join(path,\"test\")\n",
    "new_directory = \"../insect_audio/spectrograms_compressed/test\" #change if your path is different\n",
    "plt.axis('off')\n",
    "\n",
    "#Defining X_test y_test\n",
    "X_test = []  #creating a list for the images\n",
    "y_test = []  #creating the labels\n",
    "\n",
    "#go through every bird in every species\n",
    "for species in os.listdir(test_path):\n",
    "    folder_path = os.path.join(test_path, species) \n",
    "    try:\n",
    "      new_folder = os.path.join(new_directory, species)\n",
    "      os.makedirs(new_folder)\n",
    "    except: #if directory already exists, just continue\n",
    "      pass\n",
    "    for insect_image in os.listdir(folder_path):\n",
    "      image_path = os.path.join(folder_path, insect_image)\n",
    "      img = mpimg.imread(image_path) #turning image into array\n",
    "      X_test.append(img)\n",
    "      y_test.append(species)\n",
    "\n",
    "      #SDV\n",
    "      new_path = os.path.join(new_folder, insect_image)\n",
    "      red, green, blue = color_isolation(image_path) \n",
    "      n = 5 #limit of image compression (closer to 0 is higher degree), needs to be lower than lowest dimension of pixels (217)\n",
    "      new_image = compress_image(red, green, blue, n)\n",
    "      new_image.save(new_path)\n",
    "\n",
    "X_test_np = np.array(X_test)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "print(X_test_np.shape) #output dimensions (number of images,pixels_x,pixels_y,rgb)\n",
    "print(y_test_np.shape) #output dimensions (number of images,)\n",
    "\n",
    "print(\"\\nExample:\")\n",
    "img_test = X_test_np[0]\n",
    "plt.imshow(img_test)\n",
    "print(y_test_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnstOjxjAQtX"
   },
   "source": [
    "### X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "kAe6rxuPBPQX",
    "outputId": "f0fad676-f938-41cf-db2b-46ca10339025"
   },
   "outputs": [],
   "source": [
    "#going through validation images and calling functions\n",
    "valid_path = os.path.join(path,\"validation\")\n",
    "new_directory = \"../insect_audio/spectrograms_compressed/validation\" #change if your path is different\n",
    "plt.axis('off')\n",
    "\n",
    "#Defining X_valid y_valid\n",
    "X_valid = []  #creating a list for the images\n",
    "y_valid = []  #creating the labels\n",
    "\n",
    "#go through every bird in every species\n",
    "for species in os.listdir(valid_path):\n",
    "    folder_path = os.path.join(valid_path, species) \n",
    "    try:\n",
    "      new_folder = os.path.join(new_directory, species)\n",
    "      os.makedirs(new_folder)\n",
    "    except: #if directory already exists, just continue\n",
    "      pass\n",
    "    for insect_image in os.listdir(folder_path):\n",
    "      image_path = os.path.join(folder_path, insect_image)\n",
    "      img = mpimg.imread(image_path) #turning image into array\n",
    "      X_valid.append(img)\n",
    "      y_valid.append(species)\n",
    "\n",
    "      #SDV\n",
    "      new_path = os.path.join(new_folder, insect_image)\n",
    "      red, green, blue = color_isolation(image_path) \n",
    "      n = 5 #limit of image compression (closer to 0 is higher degree), needs to be lower than lowest dimension of pixels (217)\n",
    "      new_image = compress_image(red, green, blue, n)\n",
    "      new_image.save(new_path)\n",
    "\n",
    "X_valid_np = np.array(X_valid)\n",
    "y_valid_np = np.array(y_valid)\n",
    "\n",
    "print(X_valid_np.shape) #output dimensions (number of images,pixels_x,pixels_y,rgb)\n",
    "print(y_valid_np.shape) #output dimensions (number of images,)\n",
    "\n",
    "print(\"\\nExample:\")\n",
    "img_valid = X_valid_np[0]\n",
    "plt.imshow(img_valid)\n",
    "print(y_valid_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW1H9jgjBwie"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESpNmw9JBW89"
   },
   "outputs": [],
   "source": [
    "#flattening the arrays for pca, but this is WRONG\n",
    "#needs to be done for every color channel\n",
    "#tutorial (scroll past the digits) https://www.askpython.com/python/examples/principal-component-analysis-for-image-data\n",
    "\n",
    "X_train_rs = X_train_np.reshape(181, 217* 334* 4)\n",
    "X_valid_rs = X_valid_np.reshape(50, 217* 334* 4)\n",
    "X_test_rs = X_test_np.reshape(69, 217* 334* 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQqJhukUBYqa",
    "outputId": "4ceec335-c27c-49fe-e127-ed48dd781e66"
   },
   "outputs": [],
   "source": [
    "#Implementing PCA\n",
    "n_components = 40  ###probably needs to be 500+\n",
    "pca = PCA(n_components=n_components)\n",
    "pca1 = pca.fit(X_train_rs)\n",
    "X_train_pca = pca1.transform(X_train_rs)\n",
    "X_valid_pca = pca1.transform(X_valid_rs)\n",
    "X_test_pca = pca1.transform(X_test_rs)\n",
    "\n",
    "# Percentage of variance explained for the sum of each component\n",
    "print('explained variance ratio with n_components =', n_components ,': %s' % str(sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "#print(X_train_C.shape,X_pca_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fitted PCA tranformer\n",
    "import joblib\n",
    "\n",
    "joblib.dump(pca1, \"insect_audio_pca.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-8xavEQDrvn"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2V_e3N3XBa7q"
   },
   "outputs": [],
   "source": [
    "#setting the parameters for the decision tree \n",
    "param_grid_tree = {'max_depth':[2,5,8,12,16]}\n",
    "#print(\"Parameter grid:\\n{}\".format(param_grid_tree))\n",
    "\n",
    "grid_search_tree = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, cv=2)\n",
    "#fitting the model with the pca data\n",
    "grid_search_tree.fit(X_train_pca, y_train_np)\n",
    "\n",
    "#printing thebest parameters and score\n",
    "print(\"Best parameter: {}, Best cross-validation score: {:.4f}\\n\".format(grid_search_tree.best_params_,grid_search_tree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkVcr5A-Bk4w"
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 12).fit(X_train_pca, y_train_np)\n",
    "y_pred_dtc = dtc.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LLWM5z2BmZ8"
   },
   "outputs": [],
   "source": [
    "#evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test_np, y_pred_dtc)))\n",
    "#print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test_np, y_pred_dtc)))\n",
    "print(\"Weighted f1-score:\", f1_score(y_test_np, y_pred_dtc, average='weighted'))\n",
    "\n",
    "y_pred_dtc_train = dtc.predict(X_train_pca)\n",
    "print(\"Weighted training f1-score:\", f1_score(y_train_np, y_pred_dtc_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rZwdylPDwQ7"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAhuQgxjBpKr"
   },
   "outputs": [],
   "source": [
    "#Logistic regression grid search\n",
    "\n",
    "#setting logreg parameters for grid search\n",
    "param_grid_logreg = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#creating the logreg model with 100000 max iterations and 5 fold cross validation\n",
    "gs_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_logreg, cv=2)\n",
    "gs_logreg.fit(X_train_pca, y_train_np)\n",
    "\n",
    "print(\"Best parameter: {}, Best cross-validation score: {:.4f}\\n\".format(gs_logreg.best_params_,gs_logreg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUBydN_IBtPW"
   },
   "outputs": [],
   "source": [
    "#Logistic regression grid search\n",
    "\n",
    "#setting logreg parameters for grid search\n",
    "param_grid_logreg = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#creating the logreg model with 100000 max iterations and 5 fold cross validation\n",
    "gs_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_logreg, cv=2)\n",
    "gs_logreg.fit(X_train_pca, y_train_np)\n",
    "\n",
    "print(\"Best parameter: {}, Best cross-validation score: {:.4f}\\n\".format(gs_logreg.best_params_,gs_logreg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy5dpeeEBuuT"
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C = 0.01,max_iter=1000).fit(X_train_pca, y_train_np)\n",
    "pred_logreg = log_reg.predict(X_valid_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ciVOPZJBwPo"
   },
   "outputs": [],
   "source": [
    "#weighted f1 test score\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test_np, pred_logreg)))\n",
    "#print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test_np, pred_logreg)))\n",
    "print(\"Weighted f1-score:\", f1_score(y_test_np, pred_logreg, average='weighted'))\n",
    "\n",
    "y_pred_lr_train = log_reg.predict(X_train_pca)\n",
    "print(\"Weighted training f1-score:\", f1_score(y_train_np, y_pred_lr_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7R84oQTD0e7"
   },
   "source": [
    "### Grid Search (comparing and creating models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHxNXw_EBxre"
   },
   "outputs": [],
   "source": [
    "#seting the parameters\n",
    "param_grid_RF = {'max_depth':[4]} #2,4,5,8,12,16,32\n",
    "\n",
    "grid_search_RF = GridSearchCV(RandomForestClassifier(random_state=0),param_grid_RF,cv=2)\n",
    "#fitting the model with the pca data\n",
    "grid_search_RF.fit(X_train_pca,y_train_np)\n",
    "#printing the best parameter and score\n",
    "print(\"Best parameter: {}, Best cross-validation score: {:.4f}\\n\".format(grid_search_RF.best_params_,grid_search_RF.best_score_))\n",
    "\n",
    "#printing the training score\n",
    "print(\"Train Accuracy:\",grid_search_RF.score(X_train_pca,y_train_np))\n",
    "pred_RF_train = grid_search_RF.predict(X_train_pca)\n",
    "#weighted f1 training score\n",
    "print(\"weighted f1 score:\",f1_score(y_train_np,pred_RF_train,average='weighted'))\n",
    "#training confusion matrix\n",
    "#print(\"Training Confusion Matrix:\\n\",confusion_matrix(y_train_np,pred_RF_train))\n",
    "\n",
    "#testing score\n",
    "grid_search_RF_score = grid_search_RF.score(X_test_pca,y_test_np)\n",
    "print(\"\\nTest Accuracy:\",grid_search_RF_score)\n",
    "pred_RF = grid_search_RF.predict(X_test_pca)\n",
    "#weighted f1 testing score\n",
    "grid_search_RF_f1 = f1_score(y_test_np,pred_RF,average='weighted')\n",
    "print(\"weighted f1 score:\",grid_search_RF_f1)\n",
    "#testing confusion matrix\n",
    "#print(\"Testing Confusion Matrix:\\n\",confusion_matrix(y_test_np,pred_RF))\n",
    "\n",
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_m7IQcZBzYn"
   },
   "outputs": [],
   "source": [
    "#Model creation and selection\n",
    "param = {'n_neighbors':[1, 2, 5, 9]}\n",
    "\n",
    "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid = param, cv=2)\n",
    "grid_search_knn.fit(X_train_pca, y_train_np) #grid_search_knn.fit(X_train_pca, y_train)\n",
    "\n",
    "#Find the best hyperparameter\n",
    "print(\"Best parameters: {}\".format(grid_search_knn.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXU5z_SaB1Ax"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 1).fit(X_train_pca, y_train)\n",
    "y_pred_knn = knn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model to a pickle file\n",
    "import joblib\n",
    "\n",
    "joblib.dump(knn, \"insect_audio_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_T5S-DZB2NP"
   },
   "outputs": [],
   "source": [
    "#evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred_knn)))\n",
    "#print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, y_pred_knn)))\n",
    "print(\"Weighted f1-score:\", f1_score(y_test, y_pred_knn, average='weighted'))\n",
    "\n",
    "\n",
    "y_pred_knn_train = knn.predict(X_train_pca)\n",
    "print(\"Weighted training f1-score:\", f1_score(y_train_np, y_pred_knn_train, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_mV5fQUB7ND"
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "\n",
    "#setting gradient boosting grid search parameters\n",
    "param_grid_GB = {'n_estimators':[3,5,9,15,20]} #3,5,9,15,20,75,100,103,115\n",
    "\n",
    "grid_search_GB = GridSearchCV(GradientBoostingClassifier(random_state=0),param_grid_GB,cv=2)\n",
    "#fitting the grid search model\n",
    "grid_search_GB.fit(X_train_pca,y_train_np)\n",
    "\n",
    "#printing the best gradient boosting parameters and score\n",
    "print(\"Best parameter: {}, Best cross-validation score: {:.4f}\\n\".format(grid_search_GB.best_params_,grid_search_GB.best_score_))\n",
    "\n",
    "#training score\n",
    "print(\"Train Accuracy:\",grid_search_GB.score(X_train_pca,y_train_np))\n",
    "pred_GB_train = grid_search_GB.predict(X_train_pca)\n",
    "#weighted f1 training score\n",
    "print(\"\\nweighted f1 train score:\",f1_score(y_train_np,pred_GB_train,average='weighted'))\n",
    "#train confusion matrix\n",
    "print(\"\\nTraining Confusion Matrix:\\n\",confusion_matrix(y_train_np,pred_GB_train))\n",
    "\n",
    "#test score\n",
    "grid_search_GB_score = grid_search_GB.score(X_test_pca,y_test_np)\n",
    "print(\"Test Accuracy:\",grid_search_GB_score)\n",
    "pred_GB = grid_search_GB.predict(X_test_pca)\n",
    "#weighted f1 test score\n",
    "grid_search_GB_f1 = f1_score(y_test_np,pred_GB,average='weighted')\n",
    "print(\"\\nweighted f1 train score:\",grid_search_GB_f1)\n",
    "#test confusion matrix\n",
    "print(\"\\nTesting Confusion Matrix:\\n\",confusion_matrix(y_test_np,pred_GB))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNjTUg66jnywoZHJY3qEQjo",
   "collapsed_sections": [
    "ydUvZn4p0_jR",
    "DGNPUGGH1x1w",
    "VwRhXT7JAGy2",
    "wnstOjxjAQtX",
    "MW1H9jgjBwie",
    "7-8xavEQDrvn",
    "D7R84oQTD0e7"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "63a2a99283dc01513a43c4c2a710ebd131be7f6cc40ef14c5d983673f47c3534"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
